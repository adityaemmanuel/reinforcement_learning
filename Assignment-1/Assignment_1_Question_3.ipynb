{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityaemmanuel/reinforcement_learning/blob/main/Assignment-1/Assignment_1_Question_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the libraries"
      ],
      "metadata": {
        "id": "r7svKdYg__YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install pyglet==1.4\n",
        "!pip install tensorflow==2.0.0-alpha0\n",
        "!pip install autorom\n",
        "!AutoROM --accept-license\n",
        "!git clone https://github.com/DLR-RM/stable-baselines3\n",
        "%cd stable-baselines3\n",
        "!pip install -e .[docs,tests,extra]"
      ],
      "metadata": {
        "id": "KmyAEb4JABhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the required libraries\n",
        "import gym\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.ppo.policies import MlpPolicy\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Setup the initial variables\n",
        "logdir = ('./logs/assignment_q_q3')\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "1N_Gg2V2AKqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22102708-9fd2-432e-ef93-fb56fe55b559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vanilla Advantage Function"
      ],
      "metadata": {
        "id": "sCkRFI78GXxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "# From the documentation the implementation is equivalent to vanilla advantage when gae_lambda=1\n",
        "model = A2C(MlpPolicy, env, verbose=0, tensorboard_log=logdir, gae_lambda=0) \n",
        "model.learn(total_timesteps=10000)\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXKV-C4RHv0H",
        "outputId": "20e577b8-92b7-413b-ad55-7623e092d8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:26.37 +/- 4.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n-step return advantage function"
      ],
      "metadata": {
        "id": "A60oS6GWHGNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "model = A2C(MlpPolicy, env, verbose=0, tensorboard_log=logdir, n_steps=5) \n",
        "model.learn(total_timesteps=10000)\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oimunVTtHwUg",
        "outputId": "f51608da-3fd0-407f-8a50-6033bcda7731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:327.60 +/- 84.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gae advantage function"
      ],
      "metadata": {
        "id": "sfP01GlsHOej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "model = A2C(MlpPolicy, env, verbose=0, tensorboard_log=logdir, n_steps=5, gae_lambda=0.5) \n",
        "model.learn(total_timesteps=10000)\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRh_ABRWJdeC",
        "outputId": "d37544ae-e18d-4581-bce7-77697ab1d6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:129.59 +/- 15.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MC advantage function"
      ],
      "metadata": {
        "id": "MygP_ioxHUge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "model = A2C(MlpPolicy, env, verbose=0, tensorboard_log=logdir, n_steps=5, gae_lambda=0.5) \n",
        "model.learn(total_timesteps=1000)\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XKdHWl2rKYi",
        "outputId": "b5024c45-2ed6-48e2-acfa-0afd272b6ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:43.59 +/- 5.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-GSSFPkKvjxs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}